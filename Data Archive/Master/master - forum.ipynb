{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c30f36f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from numpy import random\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "import re\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_curve, auc, confusion_matrix, classification_report\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "db16af1d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>['anyone', 'else', 'intrusive', 'thought', 'co...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>['agony', 'started', 'came', 'antidepressant',...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>['two', 'week', 'taking', 'sertraline', 'mood'...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>['hi', 'honestly', 'know', 'wrong', 'going', '...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>['hi', 'one', 'like', 'birthday', 'past', 'neg...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>['able', 'control', '2', 'day', 'getting', 'mu...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>['diagnosed', 'depression', 'anxiety', 'dec', ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>['depressed', 'since', '16', 'recently', 'diag...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>['remember', 'exactly', 'last', 'time', 'last'...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>['unfortunate', 'circumstance', 'product', 'mi...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  text  label\n",
       "100  ['anyone', 'else', 'intrusive', 'thought', 'co...      0\n",
       "101  ['agony', 'started', 'came', 'antidepressant',...      0\n",
       "102  ['two', 'week', 'taking', 'sertraline', 'mood'...      0\n",
       "103  ['hi', 'honestly', 'know', 'wrong', 'going', '...      0\n",
       "104  ['hi', 'one', 'like', 'birthday', 'past', 'neg...      0\n",
       "105  ['able', 'control', '2', 'day', 'getting', 'mu...      0\n",
       "106  ['diagnosed', 'depression', 'anxiety', 'dec', ...      0\n",
       "107  ['depressed', 'since', '16', 'recently', 'diag...      0\n",
       "108  ['remember', 'exactly', 'last', 'time', 'last'...      0\n",
       "109  ['unfortunate', 'circumstance', 'product', 'mi...      0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filename_f = \"c:/users/chung/desktop/springboard_stuff/trials/model_3/depression/dep_forum_clean.csv\"\n",
    "A = pd.read_csv(filename_f)\n",
    "filename_2_f = \"c:/users/chung/desktop/springboard_stuff/trials/model_3/ptsd/ptsd_forum_clean.csv\"\n",
    "B = pd.read_csv(filename_2_f)\n",
    "filename_3_f = \"c:/users/chung/desktop/springboard_stuff/trials/model_3/cptsd/cptsd_forum_clean.csv\"\n",
    "C = pd.read_csv(filename_3_f)\n",
    "filename_4_f = \"c:/users/chung/desktop/springboard_stuff/trials/model_3/bpd/bpd_forum_clean.csv\"\n",
    "D = pd.read_csv(filename_4_f)\n",
    "filename_5_f = \"c:/users/chung/desktop/springboard_stuff/trials/model_3/bipolar/bipolar_forum_clean.csv\"\n",
    "E = pd.read_csv(filename_5_f)\n",
    "filename_6_f = \"c:/users/chung/desktop/springboard_stuff/trials/model_3/dissociation/diss_forum_clean.csv\"\n",
    "F = pd.read_csv(filename_6_f)\n",
    "\n",
    "A_ = A.dropna()\n",
    "B_ = B.dropna()\n",
    "C_ = C.dropna()\n",
    "D_ = D.dropna()\n",
    "E_ = E.dropna()\n",
    "F_ = F.dropna()\n",
    "\n",
    "master = A_.append([B_,C_,D_,E_,F_])\n",
    "master_df = pd.DataFrame(master)\n",
    "\n",
    "\n",
    "'''assigning labels and storing in variable to prepare for holdout creation'''\n",
    "df_dep = master_df.loc[master_df['label'] == 0] \n",
    "df_ptsd = master_df.loc[master_df['label'] == 1]\n",
    "df_cptsd = master_df.loc[master_df['label'] == 2] \n",
    "df_bpd = master_df.loc[master_df['label'] == 3]\n",
    "df_bipolar = master_df.loc[master_df['label'] == 4] \n",
    "df_diss = master_df.loc[master_df['label'] == 5]\n",
    "\n",
    "\n",
    "'''creating holdouts'''\n",
    "df_dep_holdout = df_dep.iloc[:100]\n",
    "df_ptsd_holdout = df_ptsd.iloc[:100]\n",
    "df_cptsd_holdout = df_cptsd.iloc[:100]\n",
    "df_bpd_holdout = df_bpd.iloc[:100]\n",
    "df_bipolar_holdout = df_bipolar.iloc[:100]\n",
    "df_diss_holdout = df_diss.iloc[:100]\n",
    "\n",
    "\n",
    "'''re-defining variables with holdout documents ommitted'''\n",
    "df_dep = df_dep.iloc[100:]\n",
    "df_ptsd = df_ptsd.iloc[100:]\n",
    "df_cptsd = df_cptsd.iloc[100:]\n",
    "df_bpd = df_bpd.iloc[100:]\n",
    "df_bipolar = df_bipolar.iloc[100:]\n",
    "df_diss = df_diss.iloc[100:]\n",
    "\n",
    "\n",
    "'''concat the pieces back together'''\n",
    "dfnew = pd.concat([df_dep, df_ptsd, df_cptsd, df_bpd, df_bipolar, df_diss])\n",
    "df_holdout = pd.concat([df_dep_holdout, df_ptsd_holdout, df_cptsd_holdout, df_bpd_holdout, df_bipolar_holdout, df_diss_holdout])\n",
    "\n",
    "dfnew.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0f955b0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                  text  label\n",
      "100  anyone else intrusive thought convince situati...      0\n",
      "101  agony started came antidepressant several year...      0\n",
      "102  two week taking sertraline mood improved bit f...      0\n",
      "103  hi honestly know wrong going honest see think ...      0\n",
      "104  hi one like birthday past negative thing big e...      0\n",
      "                                                text  label\n",
      "0                             saw today wanted share      0\n",
      "1  understand situation permanent one sure make b...      0\n",
      "2  suicidal thought really common something happe...      0\n",
      "3  want share experience read lot topic time peop...      0\n",
      "4  article talk depressive wear smile get world h...      0\n"
     ]
    }
   ],
   "source": [
    "REPLACE_BY_SPACE_RE = re.compile('[/(){}\\[\\]\\|@,;]')\n",
    "BAD_SYMBOLS_RE = re.compile('[^0-9a-z #+_]')\n",
    "STOPWORDS = set(stopwords.words('english'))\n",
    "\n",
    "def clean_text(text):\n",
    "    \"\"\"\n",
    "        text: a string\n",
    "        \n",
    "        return: modified initial string\n",
    "    \"\"\"\n",
    "    text = str(text)\n",
    "    text = text.lower() # lowercase text\n",
    "    text = REPLACE_BY_SPACE_RE.sub(' ', text) # replace REPLACE_BY_SPACE_RE symbols by space in text\n",
    "    text = BAD_SYMBOLS_RE.sub('', text) # delete symbols which are in BAD_SYMBOLS_RE from text\n",
    "    text = ' '.join(word for word in text.split() if word not in STOPWORDS) # delete stopwors from text\n",
    "    return text\n",
    "    \n",
    "dfnew['text'] = dfnew['text'].apply(clean_text)\n",
    "df_holdout['text'] = df_holdout['text'].apply(clean_text)\n",
    "\n",
    "dfnew.to_csv('master_f.csv', index=False)\n",
    "df_holdout.to_csv('master_f_holdout.csv', index=False)\n",
    "\n",
    "print(dfnew.head())\n",
    "print(df_holdout.head())\n",
    "\n",
    "X = dfnew['text'].astype(str).dropna()\n",
    "y = dfnew['label']\n",
    "\n",
    "vectorizer = TfidfVectorizer(\n",
    "    stop_words='english', \n",
    "    min_df = 5,\n",
    "    ngram_range = (1,2),\n",
    "    use_idf = True,\n",
    "    max_df = 0.5, \n",
    "    smooth_idf=True)\n",
    "\n",
    "X = vectorizer.fit_transform(X).toarray()\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X,\n",
    "    y,\n",
    "    test_size=0.2, \n",
    "    shuffle=True,\n",
    "    random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "11ca2fb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MNB\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      0.74      0.60       486\n",
      "           1       1.00      0.01      0.01       171\n",
      "           2       0.94      0.24      0.38       253\n",
      "           3       0.44      0.65      0.52       453\n",
      "           4       0.57      0.70      0.63       471\n",
      "           5       1.00      0.02      0.04       192\n",
      "\n",
      "    accuracy                           0.52      2026\n",
      "   macro avg       0.74      0.39      0.36      2026\n",
      "weighted avg       0.65      0.52      0.46      2026\n",
      "\n",
      "SGD\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.74      0.68       486\n",
      "           1       0.73      0.58      0.65       171\n",
      "           2       0.74      0.81      0.77       253\n",
      "           3       0.65      0.68      0.66       453\n",
      "           4       0.79      0.65      0.71       471\n",
      "           5       0.62      0.57      0.59       192\n",
      "\n",
      "    accuracy                           0.68      2026\n",
      "   macro avg       0.69      0.67      0.68      2026\n",
      "weighted avg       0.69      0.68      0.68      2026\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\chung\\anaconda3\\envs\\TestEnv\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOG\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.74      0.67       486\n",
      "           1       0.80      0.46      0.58       171\n",
      "           2       0.81      0.74      0.77       253\n",
      "           3       0.57      0.72      0.64       453\n",
      "           4       0.71      0.67      0.69       471\n",
      "           5       0.75      0.40      0.52       192\n",
      "\n",
      "    accuracy                           0.66      2026\n",
      "   macro avg       0.71      0.62      0.65      2026\n",
      "weighted avg       0.68      0.66      0.66      2026\n",
      "\n",
      "RF\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.58      0.75      0.66       486\n",
      "           1       0.73      0.52      0.61       171\n",
      "           2       0.77      0.68      0.72       253\n",
      "           3       0.55      0.65      0.59       453\n",
      "           4       0.73      0.69      0.71       471\n",
      "           5       0.64      0.24      0.35       192\n",
      "\n",
      "    accuracy                           0.64      2026\n",
      "   macro avg       0.67      0.59      0.61      2026\n",
      "weighted avg       0.65      0.64      0.63      2026\n",
      "\n",
      "ADA\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.58      0.58      0.58       486\n",
      "           1       0.60      0.54      0.57       171\n",
      "           2       0.60      0.50      0.55       253\n",
      "           3       0.43      0.68      0.52       453\n",
      "           4       0.79      0.55      0.65       471\n",
      "           5       0.51      0.31      0.39       192\n",
      "\n",
      "    accuracy                           0.56      2026\n",
      "   macro avg       0.58      0.53      0.54      2026\n",
      "weighted avg       0.59      0.56      0.56      2026\n",
      "\n",
      "GNB\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.41      0.49      0.45       486\n",
      "           1       0.18      0.10      0.13       171\n",
      "           2       0.63      0.37      0.47       253\n",
      "           3       0.39      0.40      0.40       453\n",
      "           4       0.39      0.50      0.44       471\n",
      "           5       0.23      0.18      0.20       192\n",
      "\n",
      "    accuracy                           0.39      2026\n",
      "   macro avg       0.37      0.34      0.35      2026\n",
      "weighted avg       0.39      0.39      0.39      2026\n",
      "\n",
      "DT\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.54      0.52      0.53       486\n",
      "           1       0.52      0.48      0.50       171\n",
      "           2       0.50      0.57      0.54       253\n",
      "           3       0.49      0.54      0.52       453\n",
      "           4       0.62      0.60      0.61       471\n",
      "           5       0.29      0.24      0.26       192\n",
      "\n",
      "    accuracy                           0.52      2026\n",
      "   macro avg       0.49      0.49      0.49      2026\n",
      "weighted avg       0.52      0.52      0.52      2026\n",
      "\n",
      "KNN\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00       486\n",
      "           1       0.00      0.00      0.00       171\n",
      "           2       0.12      0.76      0.21       253\n",
      "           3       0.24      0.15      0.18       453\n",
      "           4       0.24      0.07      0.11       471\n",
      "           5       0.50      0.01      0.02       192\n",
      "\n",
      "    accuracy                           0.15      2026\n",
      "   macro avg       0.18      0.16      0.09      2026\n",
      "weighted avg       0.17      0.15      0.10      2026\n",
      "\n",
      "DUM\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00       486\n",
      "           1       0.00      0.00      0.00       171\n",
      "           2       0.00      0.00      0.00       253\n",
      "           3       0.22      1.00      0.37       453\n",
      "           4       0.00      0.00      0.00       471\n",
      "           5       0.00      0.00      0.00       192\n",
      "\n",
      "    accuracy                           0.22      2026\n",
      "   macro avg       0.04      0.17      0.06      2026\n",
      "weighted avg       0.05      0.22      0.08      2026\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\chung\\anaconda3\\envs\\TestEnv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\chung\\anaconda3\\envs\\TestEnv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\chung\\anaconda3\\envs\\TestEnv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "model_dict={\n",
    "    'MNB': MultinomialNB(),\n",
    "    'SGD': SGDClassifier(),\n",
    "    'LOG': LogisticRegression(),\n",
    "    'RF': RandomForestClassifier(),\n",
    "    'ADA': AdaBoostClassifier(),\n",
    "    'GNB': GaussianNB(),\n",
    "    'DT': DecisionTreeClassifier(),\n",
    "    'KNN': KNeighborsClassifier(),\n",
    "    'DUM': DummyClassifier(),\n",
    "}\n",
    "\n",
    "def evaluate(model_dict, X_train, X_test, y_train, y_test):\n",
    "    \n",
    "    for k, v in model_dict.items():\n",
    "        model = v\n",
    "        model.fit(X_train, y_train)\n",
    "        y_pred = model.predict(X_test)\n",
    "\n",
    "       \n",
    "        print(k)\n",
    "        print(classification_report(y_test, y_pred))\n",
    "        \n",
    "evaluate(model_dict, X_train, X_test, y_train, y_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TestEnv",
   "language": "python",
   "name": "testenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
