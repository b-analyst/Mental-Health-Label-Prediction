{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from numpy import random\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "import re\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_curve, auc, confusion_matrix, classification_report\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>['struggling', 'sad', 'really', 'dark', 'thoug...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>['something', 'broke', 'inside', 'never', 'gon...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>['get', 'anything', 'done', 'motivation', 'wis...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>['go', 'college', 'make', 'parent', 'happy', '...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>['maybe', 'genetics', 'maybe', 'childhood', 't...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>['drank', 'yesterday', 'headache', 'cut', 'thi...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>['little', 'reading', 'functioning', 'depressi...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>['lost', 'even', 'get', 'house', 'hard', 'get'...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>['basically', 'depressed', 'year', 'told', 'pa...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>['everyday', 'getting', 'harder', 'get', 'bed'...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  text  label\n",
       "100  ['struggling', 'sad', 'really', 'dark', 'thoug...      0\n",
       "101  ['something', 'broke', 'inside', 'never', 'gon...      0\n",
       "102  ['get', 'anything', 'done', 'motivation', 'wis...      0\n",
       "103  ['go', 'college', 'make', 'parent', 'happy', '...      0\n",
       "104  ['maybe', 'genetics', 'maybe', 'childhood', 't...      0\n",
       "105  ['drank', 'yesterday', 'headache', 'cut', 'thi...      0\n",
       "106  ['little', 'reading', 'functioning', 'depressi...      0\n",
       "107  ['lost', 'even', 'get', 'house', 'hard', 'get'...      0\n",
       "108  ['basically', 'depressed', 'year', 'told', 'pa...      0\n",
       "109  ['everyday', 'getting', 'harder', 'get', 'bed'...      0"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "###Calling the subreddit data\n",
    "\n",
    "filename = \"c:/users/chung/desktop/springboard_stuff/r-depression/r-dep data cleaned.csv\"\n",
    "A = pd.read_csv(filename)\n",
    "filename_2 = \"c:/users/chung/desktop/springboard_stuff/r-ptsd/r-ptsd data cleaned.csv\"\n",
    "B = pd.read_csv(filename_2)\n",
    "filename_3 = \"c:/users/chung/desktop/springboard_stuff/r-cptsd/r-cptsd data cleaned.csv\"\n",
    "C = pd.read_csv(filename_3)\n",
    "filename_4 = \"c:/users/chung/desktop/springboard_stuff/r-bpd/r-bpd data cleaned.csv\"\n",
    "D = pd.read_csv(filename_4)\n",
    "filename_5 = \"c:/users/chung/desktop/springboard_stuff/r-bipolar/r-bipolar data cleaned.csv\"\n",
    "E = pd.read_csv(filename_5)\n",
    "filename_6 = \"c:/users/chung/desktop/springboard_stuff/r-dissociation/r-diss data cleaned.csv\"\n",
    "F = pd.read_csv(filename_6)\n",
    "\n",
    "###Combining the dataset with the appropriate labels\n",
    "# 0 = depression\n",
    "# 1 = ptsd\n",
    "# 2 = cptsd\n",
    "# 3 = bpd\n",
    "# 4 = bipolar\n",
    "# 5 = dissociation\n",
    "\n",
    "A_ = A.dropna()\n",
    "B_ = B.dropna()\n",
    "C_ = C.dropna()\n",
    "D_ = D.dropna()\n",
    "E_ = E.dropna()\n",
    "F_ = F.dropna()\n",
    "\n",
    "master = A_.append([B_,C_,D_,E_,F_])\n",
    "master_df = pd.DataFrame(master)\n",
    "master_df.to_csv('master.csv', index=False)\n",
    "\n",
    "'''assigning labels and storing in variable to prepare for holdout creation'''\n",
    "df_dep = master_df.loc[master_df['label'] == 0] \n",
    "df_ptsd = master_df.loc[master_df['label'] == 1]\n",
    "df_cptsd = master_df.loc[master_df['label'] == 2] \n",
    "df_bpd = master_df.loc[master_df['label'] == 3]\n",
    "df_bipolar = master_df.loc[master_df['label'] == 4] \n",
    "df_diss = master_df.loc[master_df['label'] == 5]\n",
    "\n",
    "\n",
    "'''creating holdouts'''\n",
    "df_dep_holdout = df_dep.iloc[:100]\n",
    "df_ptsd_holdout = df_ptsd.iloc[:100]\n",
    "df_cptsd_holdout = df_cptsd.iloc[:100]\n",
    "df_bpd_holdout = df_bpd.iloc[:100]\n",
    "df_bipolar_holdout = df_bipolar.iloc[:100]\n",
    "df_diss_holdout = df_diss.iloc[:100]\n",
    "\n",
    "\n",
    "'''re-defining variables with holdout documents ommitted'''\n",
    "df_dep = df_dep.iloc[100:]\n",
    "df_ptsd = df_ptsd.iloc[100:]\n",
    "df_cptsd = df_cptsd.iloc[100:]\n",
    "df_bpd = df_bpd.iloc[100:]\n",
    "df_bipolar = df_bipolar.iloc[100:]\n",
    "df_diss = df_diss.iloc[100:]\n",
    "\n",
    "\n",
    "'''concat the pieces back together'''\n",
    "dfnew = pd.concat([df_dep, df_ptsd, df_cptsd, df_bpd, df_bipolar, df_diss])\n",
    "df_holdout = pd.concat([df_dep_holdout, df_ptsd_holdout, df_cptsd_holdout, df_bpd_holdout, df_bipolar_holdout, df_diss_holdout])\n",
    "\n",
    "\n",
    "dfnew.head(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                  text  label\n",
      "100  struggling sad really dark thought almost 2yea...      0\n",
      "101  something broke inside never gonna alright dre...      0\n",
      "102  get anything done motivation wish world would ...      0\n",
      "103  go college make parent happy want acknowledge ...      0\n",
      "104  maybe genetics maybe childhood trauma maybe lo...      0\n",
      "                                                text  label\n",
      "0  know 16 people eye seems like easy get sorta p...      0\n",
      "1  every moment sit pain sadness another moment l...      0\n",
      "2  ever downplay anyone struggle especially come ...      0\n",
      "3  struggling bad get bed sleep spend time watchi...      0\n",
      "4  even know looking posting comment whatever lik...      0\n"
     ]
    }
   ],
   "source": [
    "REPLACE_BY_SPACE_RE = re.compile('[/(){}\\[\\]\\|@,;]')\n",
    "BAD_SYMBOLS_RE = re.compile(\"[^0-9a-z #+_]\")\n",
    "STOPWORDS = set(stopwords.words('english'))\n",
    "\n",
    "def clean_text(text):\n",
    "    \"\"\"\n",
    "        text: a string\n",
    "        \n",
    "        return: modified initial string\n",
    "    \"\"\"\n",
    "    text = str(text)\n",
    "    text = text.lower() # lowercase text\n",
    "    text = REPLACE_BY_SPACE_RE.sub(' ', text) # replace REPLACE_BY_SPACE_RE symbols by space in text\n",
    "    text = BAD_SYMBOLS_RE.sub('', text) # delete symbols which are in BAD_SYMBOLS_RE from text\n",
    "    text = ' '.join(word for word in text.split() if word not in STOPWORDS) # delete stopwors from text\n",
    "    return text\n",
    "    \n",
    "dfnew['text'] = dfnew['text'].apply(clean_text)\n",
    "df_holdout['text'] = df_holdout['text'].apply(clean_text)\n",
    "\n",
    "dfnew.to_csv('master_f.csv', index=False)\n",
    "df_holdout.to_csv('master_f_holdout.csv', index=False)\n",
    "\n",
    "print(dfnew.head())\n",
    "print(df_holdout.head())\n",
    "\n",
    "\n",
    "X = dfnew['text'].astype(str).dropna()\n",
    "y = dfnew['label']\n",
    "\n",
    "vectorizer = TfidfVectorizer(\n",
    "    stop_words='english', \n",
    "    min_df = 5,\n",
    "    ngram_range = (1,2),\n",
    "    use_idf = True,\n",
    "    max_df = 0.5, \n",
    "    smooth_idf=True)\n",
    "\n",
    "X = vectorizer.fit_transform(X).toarray()\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X,\n",
    "    y,\n",
    "    test_size=0.2, \n",
    "    shuffle=True,\n",
    "    random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MNB\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.76      0.77       581\n",
      "           1       0.72      0.74      0.73       593\n",
      "           2       0.68      0.72      0.70       611\n",
      "           3       0.45      0.84      0.58       597\n",
      "           4       0.97      0.17      0.29       543\n",
      "           5       0.86      0.71      0.78       600\n",
      "\n",
      "    accuracy                           0.66      3525\n",
      "   macro avg       0.74      0.65      0.64      3525\n",
      "weighted avg       0.74      0.66      0.65      3525\n",
      "\n",
      "SGD\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.80      0.79       581\n",
      "           1       0.84      0.77      0.80       593\n",
      "           2       0.79      0.74      0.76       611\n",
      "           3       0.88      0.79      0.83       597\n",
      "           4       0.67      0.92      0.78       543\n",
      "           5       0.87      0.78      0.82       600\n",
      "\n",
      "    accuracy                           0.80      3525\n",
      "   macro avg       0.81      0.80      0.80      3525\n",
      "weighted avg       0.81      0.80      0.80      3525\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\chung\\anaconda3\\envs\\TestEnv\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOG\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.77      0.76       581\n",
      "           1       0.81      0.73      0.77       593\n",
      "           2       0.74      0.70      0.72       611\n",
      "           3       0.83      0.76      0.79       597\n",
      "           4       0.69      0.89      0.78       543\n",
      "           5       0.81      0.76      0.78       600\n",
      "\n",
      "    accuracy                           0.77      3525\n",
      "   macro avg       0.77      0.77      0.77      3525\n",
      "weighted avg       0.77      0.77      0.77      3525\n",
      "\n",
      "RF\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.85      0.76       581\n",
      "           1       0.88      0.79      0.83       593\n",
      "           2       0.84      0.77      0.80       611\n",
      "           3       0.85      0.83      0.84       597\n",
      "           4       0.77      0.90      0.83       543\n",
      "           5       0.93      0.78      0.85       600\n",
      "\n",
      "    accuracy                           0.82      3525\n",
      "   macro avg       0.83      0.82      0.82      3525\n",
      "weighted avg       0.83      0.82      0.82      3525\n",
      "\n",
      "ADA\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.54      0.52      0.53       581\n",
      "           1       0.68      0.50      0.58       593\n",
      "           2       0.54      0.45      0.49       611\n",
      "           3       0.61      0.59      0.60       597\n",
      "           4       0.52      0.86      0.65       543\n",
      "           5       0.67      0.61      0.64       600\n",
      "\n",
      "    accuracy                           0.59      3525\n",
      "   macro avg       0.60      0.59      0.58      3525\n",
      "weighted avg       0.60      0.59      0.58      3525\n",
      "\n",
      "GNB\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.66      0.68       581\n",
      "           1       0.69      0.70      0.69       593\n",
      "           2       0.62      0.70      0.66       611\n",
      "           3       0.68      0.72      0.70       597\n",
      "           4       0.73      0.83      0.78       543\n",
      "           5       0.85      0.63      0.72       600\n",
      "\n",
      "    accuracy                           0.70      3525\n",
      "   macro avg       0.71      0.71      0.71      3525\n",
      "weighted avg       0.71      0.70      0.70      3525\n",
      "\n",
      "DT\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.74      0.72       581\n",
      "           1       0.76      0.77      0.77       593\n",
      "           2       0.74      0.73      0.74       611\n",
      "           3       0.79      0.78      0.79       597\n",
      "           4       0.75      0.88      0.81       543\n",
      "           5       0.88      0.72      0.79       600\n",
      "\n",
      "    accuracy                           0.77      3525\n",
      "   macro avg       0.77      0.77      0.77      3525\n",
      "weighted avg       0.77      0.77      0.77      3525\n",
      "\n",
      "KNN\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.02      0.04       581\n",
      "           1       0.81      0.04      0.08       593\n",
      "           2       0.61      0.10      0.17       611\n",
      "           3       0.81      0.02      0.04       597\n",
      "           4       0.18      0.96      0.30       543\n",
      "           5       0.39      0.28      0.33       600\n",
      "\n",
      "    accuracy                           0.23      3525\n",
      "   macro avg       0.62      0.24      0.16      3525\n",
      "weighted avg       0.63      0.23      0.16      3525\n",
      "\n",
      "DUM\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00       581\n",
      "           1       0.00      0.00      0.00       593\n",
      "           2       0.00      0.00      0.00       611\n",
      "           3       0.17      1.00      0.29       597\n",
      "           4       0.00      0.00      0.00       543\n",
      "           5       0.00      0.00      0.00       600\n",
      "\n",
      "    accuracy                           0.17      3525\n",
      "   macro avg       0.03      0.17      0.05      3525\n",
      "weighted avg       0.03      0.17      0.05      3525\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\chung\\anaconda3\\envs\\TestEnv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\chung\\anaconda3\\envs\\TestEnv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\chung\\anaconda3\\envs\\TestEnv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "model_dict={\n",
    "    'MNB': MultinomialNB(),\n",
    "    'SGD': SGDClassifier(),\n",
    "    'LOG': LogisticRegression(),\n",
    "    'RF': RandomForestClassifier(),\n",
    "    'ADA': AdaBoostClassifier(),\n",
    "    'GNB': GaussianNB(),\n",
    "    'DT': DecisionTreeClassifier(),\n",
    "    'KNN': KNeighborsClassifier(),\n",
    "    'DUM': DummyClassifier(),\n",
    "}\n",
    "\n",
    "def evaluate(model_dict, X_train, X_test, y_train, y_test):\n",
    "    \n",
    "    for k, v in model_dict.items():\n",
    "        model = v\n",
    "        model.fit(X_train, y_train)\n",
    "        y_pred = model.predict(X_test)\n",
    "\n",
    "       \n",
    "        print(k)\n",
    "        print(classification_report(y_test, y_pred))\n",
    "        \n",
    "evaluate(model_dict, X_train, X_test, y_train, y_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
